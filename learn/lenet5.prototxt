name: "forward"

layer{
  type: "PlaceholderOp"
  top: "arg0_1"
  layer_param{
    shape: [64, 3, 5, 5]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg1_1"
  layer_param{
    shape: [1, 3, 32, 32]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg2_1"
  layer_param{
    shape: [128, 64, 3, 3]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg3_1"
  layer_param{
    shape: [128, 128, 5, 5]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg4_1"
  layer_param{
    shape: [128, 512]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg5_1"
  layer_param{
    shape: [64, 128]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "PlaceholderOp"
  top: "arg6_1"
  layer_param{
    shape: [10, 64]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "Conv2dOp"
  top: "convolution"
  bottom: "arg1_1"
  bottom: "arg0_1"
  layer_param{
    attr_0: None
    attr_1: [1, 1]
    attr_2: [0, 0]
    attr_3: [1, 1]
    attr_4: False
    attr_5: [0, 0]
    attr_6: 1
    shape: [1, 64, 28, 28]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "ReluOp"
  top: "relu"
  bottom: "convolution"
  layer_param{
    shape: [1, 64, 28, 28]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "MaxPool2dOp"
  top: "getitem"
  bottom: "relu"
  layer_param{
    attr_0: [2, 2]
    attr_1: [2, 2]
    shape: [1, 64, 14, 14]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "Conv2dOp"
  top: "convolution_1"
  bottom: "getitem"
  bottom: "arg2_1"
  layer_param{
    attr_0: None
    attr_1: [1, 1]
    attr_2: [0, 0]
    attr_3: [1, 1]
    attr_4: False
    attr_5: [0, 0]
    attr_6: 1
    shape: [1, 128, 12, 12]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "ReluOp"
  top: "relu_1"
  bottom: "convolution_1"
  layer_param{
    shape: [1, 128, 12, 12]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "MaxPool2dOp"
  top: "getitem_2"
  bottom: "relu_1"
  layer_param{
    attr_0: [2, 2]
    attr_1: [2, 2]
    shape: [1, 128, 6, 6]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "Conv2dOp"
  top: "convolution_2"
  bottom: "getitem_2"
  bottom: "arg3_1"
  layer_param{
    attr_0: None
    attr_1: [1, 1]
    attr_2: [0, 0]
    attr_3: [1, 1]
    attr_4: False
    attr_5: [0, 0]
    attr_6: 1
    shape: [1, 128, 2, 2]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "ViewOp"
  top: "view"
  bottom: "convolution_2"
  layer_param{
    attr_0: [1, 512]
    shape: [1, 512]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "TransposeOp"
  top: "t"
  bottom: "arg4_1"
  layer_param{
    shape: [512, 128]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "MatmulOp"
  top: "mm"
  bottom: "view"
  bottom: "t"
  layer_param{
    shape: [1, 128]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "ReluOp"
  top: "relu_2"
  bottom: "mm"
  layer_param{
    shape: [1, 128]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "TransposeOp"
  top: "t_1"
  bottom: "arg5_1"
  layer_param{
    shape: [128, 64]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "MatmulOp"
  top: "mm_1"
  bottom: "relu_2"
  bottom: "t_1"
  layer_param{
    shape: [1, 64]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "ReluOp"
  top: "relu_3"
  bottom: "mm_1"
  layer_param{
    shape: [1, 64]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "TransposeOp"
  top: "t_2"
  bottom: "arg6_1"
  layer_param{
    shape: [64, 10]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "MatmulOp"
  top: "mm_2"
  bottom: "relu_3"
  bottom: "t_2"
  layer_param{
    shape: [1, 10]
    dtype: "TensorDType.Float32"
  }
}

layer{
  type: "OutputOp"
  top: "output"
  bottom: "mm_2"
}
